from google.cloud import aiplatform as vertexai
import datetime
from google_cloud_pipeline_components import aiplatform as gcc_aip
from kfp.v2 import dsl,compiler


PATH=%env PATH
%env PATH={PATH}:/home/jupyter/.local/bin

PROJECT_ID = *****
REGION = *****

GCS_BUCKET = f"gs://{PROJECT_ID}"

vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)

MODEL_DIR = "restaurant-profitability-prediction"
ARTIFACT_REGISTRY="restaurant-profitability-prediction"

IMAGE_NAME="restaurant-profitability-prediction"
IMAGE_TAG="latest"
IMAGE_URI=f"{REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACT_REGISTRY}/{IMAGE_NAME}:{IMAGE_TAG}"


#run it one time of the bucket is new
!gsutil mb -l $REGION $GCS_BUCKET 

#run it one time of the artifact is new
!gcloud artifacts repositories create $ARTIFACT_REGISTRY --location=$REGION --repository-format='docker' --description='Docker repository for sentiment model' 

cloudbuild_yaml = f"""steps:
- name: 'gcr.io/cloud-builders/docker'
  args: [ 'build', '-t', '{IMAGE_URI}', '.' ]
images: 
- '{IMAGE_URI}'"""

with open(f"{MODEL_DIR}/cloudbuild.yaml", "w") as fp:
    fp.write(cloudbuild_yaml)


con = f"{MODEL_DIR}/cloudbuild.yaml"
!gcloud builds submit --config=$con --timeout=1200 $MODEL_DIR


TIMESTAMP=datetime.datetime.now().strftime('%Y%m%d%H%M%S')
DISPLAY_NAME = "restaurant-profitability-{}".format(TIMESTAMP)
GCS_BASE_OUTPUT_DIR= f"{GCS_BUCKET}/{MODEL_DIR}-{TIMESTAMP}"

USER = "admin@amirmeimand.altostrat.com"  # TODO: change this to your name.
PIPELINE_ROOT = "{}/pipeline_root/{}".format(GCS_BUCKET, USER)

SERVING_IMAGE_URI = "us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-11:latest"


@dsl.pipeline(name="restaurant-profitability-prediction", pipeline_root=PIPELINE_ROOT)
def pipeline(
    project: str = PROJECT_ID,
    location: str = REGION,
    staging_bucket: str = GCS_BUCKET,
    display_name: str = DISPLAY_NAME,    
    container_uri: str = IMAGE_URI,
    model_serving_container_image_uri: str = SERVING_IMAGE_URI,    
    base_output_dir: str = GCS_BASE_OUTPUT_DIR
):
    
    
    model_train_evaluate_op = gcc_aip.CustomContainerTrainingJobRunOp(
        # Vertex AI Python SDK authentication parameters.        
        project=project,
        location=location,
        staging_bucket=staging_bucket,
        # WorkerPool arguments.
        replica_count=1,
        machine_type="e2-standard-4",    
        display_name=display_name,
        container_uri=container_uri,        
        base_output_dir=base_output_dir        
    )    
    
compiler.Compiler().compile(
    pipeline_func=pipeline, package_path="restaurant-profitability-prediction.json"
)

vertex_pipelines_job = vertexai.pipeline_jobs.PipelineJob(
    display_name="restaurant-profitability-prediction",
    template_path="restaurant-profitability-prediction.json",
    parameter_values={
        "project": PROJECT_ID,
        "location": REGION,        
        "staging_bucket": GCS_BUCKET,
        "display_name": DISPLAY_NAME,        
        "container_uri": IMAGE_URI,
        "model_serving_container_image_uri": SERVING_IMAGE_URI,        
        "base_output_dir": GCS_BASE_OUTPUT_DIR},
    enable_caching=True,
)

vertex_pipelines_job.run()

